{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use EDA to get insights on the data, understand if it is shuffled, encrypted and scaled\n",
    "- When doing EDA, visualization is very important, but even before, try looking into every column to understand it and try to create a new column \n",
    "- After going through every colmun and undertanding it, you may need to run describe() on every column to check if there are any abnormalities example age 336\n",
    "- Look out if during validation the plots of the test set where different than that of the training set\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the colmn names are anonymized and even maube the content is as well, first thisng is we:\n",
    "- Divide data into data types\n",
    "- Find how feature relate to each other or if they are grouped in some way\n",
    "- Run feature importance on the columns, and if a column looks special maybe further investigate it\n",
    "- Maybe check if the data was scaled and try to scale it back\n",
    "- A trick will be to check if the data is scaled is to run mean and std, and if the value equals 1 then it was standard scaled\n",
    "- Then take a unique values of that feature and run unique() then np.diff() to see the difference between 2 consecutive numbers to see the distance between numbers\n",
    "- Then divide the feature by the distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand how the data was generated and how where samples generated\n",
    "- Maybe they oversampled a partical class during sampling\n",
    "- If test set was generated different from train set, then we can't use part of the test set for our validation set\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
